{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "00c67d37",
   "metadata": {},
   "source": [
    "# TOV Emulator to train a NN to predict just Tidal deformability of a Neutron Star from a Neuclear EOS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a069fca5",
   "metadata": {},
   "source": [
    "### <div style= 'color: goldenrod'> Import all the required modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8f6b2ebf-5f02-4974-899d-31d68abf69b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from numpy import pi as pi\n",
    "from scipy.integrate import odeint\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import time # to meaasure execution time of code blocks\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "\n",
    "# Custom modules\n",
    "import eos # generates EOS tables. Returns energy density, pressure, etc. for given set of EOS parameters. \n",
    "import tov # solves TOV equations and returns mass and radius for a given EOS and central pressure\n",
    "import tov_tide # solves TOV equations including tidal deformability calculations, for neutron star tidal effects in binaries.\n",
    "\n",
    "\n",
    "%matplotlib widget"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00b6c96f",
   "metadata": {},
   "source": [
    "### <div style= 'color: goldenrod'> Define the following functions:\n",
    "$EoS(\\theta)$:\n",
    "Generate the energy density and pressure arrays for a given EOS parameter set.\n",
    "\n",
    "$find\\_first\\_maxima$:\n",
    "Find first local maxima (to get NS mass)\n",
    "\n",
    "$get\\_MR\\_pc$:\n",
    "Solve TOV equations to get mass-radius points for an array of central pressures.\n",
    "\n",
    "$get\\_MRL\\_pc$:\n",
    "Solve TOV equations to get mass, radius and tidal deformability points for an array of central pressures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "db23591c-6f82-4bb1-963e-1203c965a9cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "dkm = 1.3234e-6 # conversion of energy density and pressure from Mev/fm^3 to km^-2\n",
    "conv = 197.33**3 # MeV/fm3 is roughly h_bar * c in natural units\n",
    "pcmin = 1.33e-6 # Fiducial minimum central pressure used when generating neutron star sequences\n",
    "                # Ensures TOV solver starts with a non-zero pressure \n",
    "\n",
    "\n",
    "def EoS(θ):\n",
    "    \"\"\"\n",
    "    Generate the energy density and pressure arrays for a given EOS parameter set.\n",
    "    Returns Energy and pressure array given given eos parameters and if eos is not montonic returns nan.\n",
    "    \n",
    "    Parameters:\n",
    "    ----------\n",
    "    θ = [L0, Ksym]: parameters of the nuclear EOS.\n",
    "            \n",
    "            L0: slope of symmetry energy. Controls how neutron-rich matter pressure grows with density.\n",
    "            Ksym: curvature of symmetry energy. Determines how “stiff” the EOS is for neutron-rich matter at higher densities.\n",
    "    \n",
    "    Returns:\n",
    "    -------\n",
    "    nb: baryon number density array\n",
    "    ener: energy density at each density point array\n",
    "    pres: pressure at each density point array\n",
    "    cs: speed of sound array\n",
    "    icc: flag if EOS is causal or monotonic\n",
    "\n",
    "    \"\"\"\n",
    "    L0, Ksym = θ[0], θ[1]\n",
    "    # Calling the eos.eos module\n",
    "    index, nb, pressure, energy, cs, icc = eos.eos(L0, Ksym, 1.6, 3.0, 6.2, 3.7, 2.4, 2.6)\n",
    "    # Truncate arrays up to index-1 to ensure valid, monotonic EOS.\n",
    "    nb = nb[0:index-1] \n",
    "    pressure = pressure[0:index-1]\n",
    "    energy = energy[0:index-1]\n",
    "    cs = cs[0:index-1]\n",
    "    # Converts pressure and energy to km^-2 units\n",
    "    pres = pressure * dkm\n",
    "    ener = energy * dkm\n",
    "    return ener, pres, nb, cs, icc\n",
    "\n",
    "################################################################################\n",
    "\n",
    "def get_MR_pc(θ, pc):\n",
    "    \"\"\"\n",
    "    Solve TOV equations to get mass-radius points for an array of central pressures.\n",
    "\n",
    "    Parameters:\n",
    "    ----------\n",
    "    θ: [L0, Ksym] EOS parameters\n",
    "    pc: array of entral pressures\n",
    "\n",
    "    Returns:\n",
    "    -------\n",
    "    M: List of Masses\n",
    "    R: List of Radiuses corresponding to each central pressure\n",
    "\n",
    "    \"\"\"\n",
    "    M=[]\n",
    "    R=[]\n",
    "    for i in pc:\n",
    "        L0, Ksym = θ[0], θ[1]\n",
    "        # Calling the eos.eos module\n",
    "        index, nb, pressure, energy, cs, icc = eos.eos(L0, Ksym, 1.6, 3.0, 6.2, 3.7, 2.4, 2.6)\n",
    "        pressure = pressure[0:index-1]\n",
    "        energy = energy[0:index-1]\n",
    "        pres = pressure * dkm\n",
    "        ener = energy * dkm\n",
    "        # Calling the tov.tov module\n",
    "        m, r = tov.tov(ener, pres, [i])\n",
    "        M.append(m)\n",
    "        R.append(r)\n",
    "    return M, R\n",
    "    \n",
    "################################################################################\n",
    "\n",
    "def get_MRL_pc(θ, pc):\n",
    "    \"\"\"\n",
    "    Solve TOV equations to get mass, radius and tidal deformability points for an array of central pressures.\n",
    "\n",
    "    Parameters:\n",
    "    ----------\n",
    "    θ: [L0, Ksym] EOS parameters\n",
    "    pc: array of central pressures\n",
    "\n",
    "    Returns:\n",
    "    -------\n",
    "    M: List of Masses\n",
    "    R: List of Radiuses \n",
    "    L: List of Tidal deformabilities corresponding to each central pressure\n",
    "    \"\"\"\n",
    "    M=[]\n",
    "    R=[]\n",
    "    L=[]\n",
    "    for i in pc:\n",
    "        L0, Ksym = θ[0] ,θ[1]\n",
    "        # Calling the eos.eos module\n",
    "        index, nb, pressure, energy, cs, icc = eos.eos(L0, Ksym, 1.6, 3.0, 6.2, 3.7, 2.4, 2.6)\n",
    "        pressure = pressure[0:index-1]\n",
    "        energy = energy[0:index-1]\n",
    "        pres = pressure * dkm\n",
    "        ener = energy * dkm\n",
    "        # Calling the tov_tide.tov_tide module\n",
    "        m, r, td = tov_tide.tov_tide(ener, pres, [i])\n",
    "        M.append(m)\n",
    "        R.append(r)\n",
    "        L.append(td)\n",
    "    return M, R, L\n",
    "\n",
    "################################################################################\n",
    "\n",
    "def find_first_maxima(arr):\n",
    "    \"\"\"\n",
    "    Identify the first peak in a 1D array (used to find maximum neutron star mass).\n",
    "    Loops through array to check if an element is larger than its neighbors → first local maximum.\n",
    "    If no local maxima found, returns global maximum as fallback.\n",
    "\n",
    "    Parameters:\n",
    "    ----------\n",
    "    arr: mass array\n",
    "\n",
    "    Returns:\n",
    "    -------\n",
    "    max_index: index of the first maxima\n",
    "    arr[max_index]: mass value of the first maxima\n",
    "\n",
    "    \"\"\"\n",
    "    for i in range(1, len(arr) - 1):\n",
    "        if arr[i] > arr[i - 1] and arr[i] > arr[i + 1]:\n",
    "            return i, arr[i]  # Return the index and the value of the first maxima\n",
    "    max_index = np.argmax(arr)\n",
    "    return max_index, arr[max_index]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37ae57b5",
   "metadata": {},
   "source": [
    "### <div style= 'color: yellow'> Load the generated dataset, normalizing it and splitting into training and validation datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f87ef44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset preview with 5000 samples:\n",
      "     log_pc          L      Ksym      Mass     Radius  TidalDeformability\n",
      "0 -5.876148  67.222565  94.98584  0.098961  68.013624        2.777602e+09\n",
      "1 -5.815919  67.222565  94.98584  0.106096  44.336073        3.516634e+08\n",
      "2 -5.755689  67.222565  94.98584  0.115584  32.775766        1.100296e+08\n",
      "3 -5.695460  67.222565  94.98584  0.127311  26.241373        5.160710e+07\n",
      "4 -5.635230  67.222565  94.98584  0.141338  22.179715        2.802392e+07\n",
      "5 -5.575000  67.222565  94.98584  0.157765  19.496382        1.610186e+07\n",
      "6 -5.514771  67.222565  94.98584  0.176675  17.649795        9.494694e+06\n",
      "7 -5.454541  67.222565  94.98584  0.198265  16.337010        5.676452e+06\n",
      "8 -5.394311  67.222565  94.98584  0.222691  15.385547        3.425194e+06\n",
      "9 -5.334082  67.222565  94.98584  0.250110  14.687632        2.084140e+06\n",
      "tensor([[2.7776e+09],\n",
      "        [3.5166e+08],\n",
      "        [1.1003e+08],\n",
      "        ...,\n",
      "        [1.0220e+01],\n",
      "        [8.5420e+00],\n",
      "        [7.2195e+00]])\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "num_samples = 5000 #############################################################\n",
    "\n",
    "# Load dataset saved with np.savez\n",
    "dataset_name = f\"EOS_dataset_{num_samples}samples.npz\"\n",
    "dataset_loc = \"/home/kay/ML-for-Neutron-Stars/COMMA_emulator/Outputs-Kay/Datasets/\"\n",
    "data = np.load(dataset_loc+dataset_name)\n",
    "\n",
    "# Extract columns\n",
    "log_pc_samples = data['log_pc_samples']     # shape: (N,)\n",
    "valid_EOS_params = data['valid_EOS_params'] # shape: (N, 2)\n",
    "MRL_data = data['MRL_data']                 # shape: (N, 3)\n",
    "\n",
    "# Visualizing the dataset\n",
    "df = pd.DataFrame(\n",
    "    np.column_stack([log_pc_samples, valid_EOS_params, MRL_data]),\n",
    "    columns=[\"log_pc\", \"L\", \"Ksym\", \"Mass\", \"Radius\", \"TidalDeformability\"]\n",
    ")\n",
    "n = int(re.search(r\"\\d+\", dataset_name).group())\n",
    "print(f\"Dataset preview with {n} samples:\")\n",
    "print(df.head(10))  # nicely formatted table of the first 10 values\n",
    "\n",
    "# Prepare X (features) and y (targets)\n",
    "X_eos = torch.tensor(np.column_stack([log_pc_samples, valid_EOS_params]), dtype=torch.float32)  # pc, L, Ksym\n",
    "y_eos = torch.tensor(MRL_data[ : , 2:3], dtype=torch.float32)  # Tidal deformability (target)\n",
    "print(y_eos)\n",
    "\n",
    "# Apply log scaling to the target\n",
    "y_eos_log = torch.log10(y_eos + 1e-8)   # +eps to avoid log(0)\n",
    "\n",
    "# Normalize the dataset\n",
    "X_eos_mean, X_eos_std = X_eos.mean(dim=0), X_eos.std(dim=0)\n",
    "y_eos_mean, y_eos_std = y_eos_log.mean(dim=0), y_eos_log.std(dim=0)\n",
    "X_eos_norm = (X_eos - X_eos_mean) / X_eos_std\n",
    "y_eos_norm = (y_eos_log - y_eos_mean) / y_eos_std\n",
    "\n",
    "# Split into training and validation sets\n",
    "train_size = int(0.8 * len(X_eos_norm))\n",
    "X_eos_train, X_eos_val = X_eos_norm[:train_size], X_eos_norm[train_size:]\n",
    "y_eos_train, y_eos_val = y_eos_norm[:train_size], y_eos_norm[train_size:]\n",
    "\n",
    "# Convert data to PyTorch tensors\n",
    "X_eos_train, y_eos_train = X_eos_train.view(-1, 3), y_eos_train.view(-1, 1)\n",
    "X_eos_val, y_eos_val = X_eos_val.view(-1, 3), y_eos_val.view(-1, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6fd97a5",
   "metadata": {},
   "source": [
    "### <div style= 'color: yellow'> Defining and training the NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1aaaecae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set model number for saving\n",
    "Model_num = \"TD_Model5\" ###########################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24340c79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Neural Network for EOS predictions\n",
    "class HybridPP_EOS_NN(nn.Module):\n",
    "    def __init__(self, input_dim=3, hidden_dim=64, output_dim=1): #############\n",
    "        super(HybridPP_EOS_NN, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, hidden_dim)\n",
    "        self.fc2 = nn.Linear(hidden_dim, hidden_dim//2)\n",
    "        self.fc3 = nn.Linear(hidden_dim//2, hidden_dim//3)\n",
    "        self.fc4 = nn.Linear(hidden_dim//3, output_dim)\n",
    "        self.reLU = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(p=0.2) # Dropout layer for regularization\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.reLU(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.reLU(self.fc2(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.reLU(self.fc3(x))\n",
    "        x = self.dropout(x)\n",
    "        return self.fc4(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dd591de-f663-4c7a-8fa8-fad78b8a9bc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [100/10000],\n",
      "              Training Loss: 0.0108,\n",
      "              Validation Loss: 0.0102\n",
      "Epoch [200/10000],\n",
      "              Training Loss: 0.0107,\n",
      "              Validation Loss: 0.0102\n",
      "Epoch [300/10000],\n",
      "              Training Loss: 0.0107,\n",
      "              Validation Loss: 0.0102\n",
      "Epoch [400/10000],\n",
      "              Training Loss: 0.0107,\n",
      "              Validation Loss: 0.0101\n",
      "Epoch [500/10000],\n",
      "              Training Loss: 0.0106,\n",
      "              Validation Loss: 0.0101\n",
      "Epoch [600/10000],\n",
      "              Training Loss: 0.0106,\n",
      "              Validation Loss: 0.0100\n",
      "Epoch [700/10000],\n",
      "              Training Loss: 0.0105,\n",
      "              Validation Loss: 0.0099\n",
      "Epoch [800/10000],\n",
      "              Training Loss: 0.0103,\n",
      "              Validation Loss: 0.0098\n",
      "Epoch [900/10000],\n",
      "              Training Loss: 0.0101,\n",
      "              Validation Loss: 0.0096\n",
      "Epoch [1000/10000],\n",
      "              Training Loss: 0.0100,\n",
      "              Validation Loss: 0.0094\n",
      "Epoch [1100/10000],\n",
      "              Training Loss: 0.0097,\n",
      "              Validation Loss: 0.0092\n",
      "Epoch [1200/10000],\n",
      "              Training Loss: 0.0094,\n",
      "              Validation Loss: 0.0090\n",
      "Epoch [1300/10000],\n",
      "              Training Loss: 0.0091,\n",
      "              Validation Loss: 0.0087\n",
      "Epoch [1400/10000],\n",
      "              Training Loss: 0.0089,\n",
      "              Validation Loss: 0.0084\n",
      "Epoch [1500/10000],\n",
      "              Training Loss: 0.0085,\n",
      "              Validation Loss: 0.0081\n",
      "Epoch [1600/10000],\n",
      "              Training Loss: 0.0081,\n",
      "              Validation Loss: 0.0078\n",
      "Epoch [1700/10000],\n",
      "              Training Loss: 0.0078,\n",
      "              Validation Loss: 0.0074\n",
      "Epoch [1800/10000],\n",
      "              Training Loss: 0.0074,\n",
      "              Validation Loss: 0.0071\n",
      "Epoch [1900/10000],\n",
      "              Training Loss: 0.0067,\n",
      "              Validation Loss: 0.0065\n",
      "Epoch [2000/10000],\n",
      "              Training Loss: 0.0062,\n",
      "              Validation Loss: 0.0058\n",
      "Epoch [2100/10000],\n",
      "              Training Loss: 0.0058,\n",
      "              Validation Loss: 0.0051\n",
      "Epoch [2200/10000],\n",
      "              Training Loss: 0.0052,\n",
      "              Validation Loss: 0.0045\n",
      "Epoch [2300/10000],\n",
      "              Training Loss: 0.0045,\n",
      "              Validation Loss: 0.0039\n",
      "Epoch [2400/10000],\n",
      "              Training Loss: 0.0042,\n",
      "              Validation Loss: 0.0033\n",
      "Epoch [2500/10000],\n",
      "              Training Loss: 0.0039,\n",
      "              Validation Loss: 0.0032\n",
      "Epoch [2600/10000],\n",
      "              Training Loss: 0.0035,\n",
      "              Validation Loss: 0.0030\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 52\u001b[0m\n\u001b[1;32m     50\u001b[0m model_eos\u001b[38;5;241m.\u001b[39mtrain() \u001b[38;5;66;03m# Training mode\u001b[39;00m\n\u001b[1;32m     51\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad() \u001b[38;5;66;03m# Erase the record of gradients\u001b[39;00m\n\u001b[0;32m---> 52\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel_eos\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_eos_train\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# Forward pass\u001b[39;00m\n\u001b[1;32m     53\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(outputs, y_eos_train) \u001b[38;5;66;03m# Compute training loss\u001b[39;00m\n\u001b[1;32m     54\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward() \u001b[38;5;66;03m# Backward propogate the training loss\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/ML/lib/python3.10/site-packages/torch/nn/modules/module.py:1751\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1749\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1751\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/ML/lib/python3.10/site-packages/torch/nn/modules/module.py:1762\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1757\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1758\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1760\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1761\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1762\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1764\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1765\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "Cell \u001b[0;32mIn[5], line 14\u001b[0m, in \u001b[0;36mHybridPP_EOS_NN.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[1;32m     13\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreLU(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfc1(x))\n\u001b[0;32m---> 14\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdropout\u001b[49m(x)\n\u001b[1;32m     15\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreLU(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfc2(x))\n\u001b[1;32m     16\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout(x)\n",
      "File \u001b[0;32m~/miniconda3/envs/ML/lib/python3.10/site-packages/torch/nn/modules/module.py:1927\u001b[0m, in \u001b[0;36mModule.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1922\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;241m=\u001b[39m OrderedDict()\n\u001b[1;32m   1924\u001b[0m \u001b[38;5;66;03m# It is crucial that the return type is not annotated as `Any`, otherwise type checking\u001b[39;00m\n\u001b[1;32m   1925\u001b[0m \u001b[38;5;66;03m# on `torch.nn.Module` and all its subclasses is largely disabled as a result. See:\u001b[39;00m\n\u001b[1;32m   1926\u001b[0m \u001b[38;5;66;03m# https://github.com/pytorch/pytorch/pull/115074\u001b[39;00m\n\u001b[0;32m-> 1927\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__getattr__\u001b[39m(\u001b[38;5;28mself\u001b[39m, name: \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Union[Tensor, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModule\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[1;32m   1928\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_parameters\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__dict__\u001b[39m:\n\u001b[1;32m   1929\u001b[0m         _parameters \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__dict__\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_parameters\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Initialize and train the model\n",
    "model_eos = HybridPP_EOS_NN()\n",
    "criterion = nn.HuberLoss(delta=0.5)\n",
    "optimizer = optim.Adam(model_eos.parameters(), lr=5e-4) #######################\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "epochs = 10000 #################################################################\n",
    "training_losses = []\n",
    "val_losses = []\n",
    "\n",
    "best_val_loss = float('inf')\n",
    "patience = 300  # Number of epochs to wait for improvement before stopping\n",
    "patience_counter = 0\n",
    "\n",
    "# # Batching the data\n",
    "# batch_size = 16  ###############################################################\n",
    "\n",
    "# train_dataset = TensorDataset(X_eos_train, y_eos_train)\n",
    "# val_dataset = TensorDataset(X_eos_val, y_eos_val)\n",
    "\n",
    "# train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "# val_loader = DataLoader(val_dataset, batch_size=batch_size)\n",
    "\n",
    "# for epoch in range(epochs):\n",
    "#     model_eos.train()\n",
    "#     epoch_train_loss = 0\n",
    "#     for X_batch, y_batch in train_loader:\n",
    "#         optimizer.zero_grad()\n",
    "#         outputs = model_eos(X_batch)\n",
    "#         loss = criterion(outputs, y_batch)\n",
    "#         loss.backward()\n",
    "#         optimizer.step()\n",
    "#         epoch_train_loss += loss.item() * X_batch.size(0)\n",
    "#     training_losses.append(epoch_train_loss / len(train_loader.dataset))\n",
    "\n",
    "#     # Validation\n",
    "#     model_eos.eval()\n",
    "#     epoch_val_loss = 0\n",
    "#     with torch.no_grad():\n",
    "#         for X_batch, y_batch in val_loader:\n",
    "#             val_outputs = model_eos(X_batch)\n",
    "#             val_loss = criterion(val_outputs, y_batch)\n",
    "#             epoch_val_loss += val_loss.item() * X_batch.size(0)\n",
    "#     val_losses.append(epoch_val_loss / len(val_loader.dataset))\n",
    "\n",
    "# Without batching (original code)\n",
    "for epoch in range(epochs):\n",
    "    # Training\n",
    "    model_eos.train() # Training mode\n",
    "    optimizer.zero_grad() # Erase the record of gradients\n",
    "    outputs = model_eos(X_eos_train) # Forward pass\n",
    "    loss = criterion(outputs, y_eos_train) # Compute training loss\n",
    "    loss.backward() # Backward propogate the training loss\n",
    "    optimizer.step()\n",
    "    training_losses.append(loss.item())\n",
    "\n",
    "    # Validation\n",
    "    model_eos.eval() # Validation mode\n",
    "    with torch.no_grad():\n",
    "        val_outputs = model_eos(X_eos_val)\n",
    "        val_loss = criterion(val_outputs, y_eos_val)\n",
    "        val_losses.append(val_loss.item())\n",
    "\n",
    "    # Early stopping check\n",
    "    if val_loss.item() < best_val_loss:\n",
    "        best_val_loss = val_loss.item()\n",
    "        patience_counter = 0\n",
    "        # Save the best model weights\n",
    "        best_model_state = model_eos.state_dict()\n",
    "    else:\n",
    "        patience_counter += 1\n",
    "        if patience_counter >= patience:\n",
    "            print(f\"Early stopping at epoch {epoch+1}\")\n",
    "            break\n",
    "\n",
    "    # Print progress every 100 epochs\n",
    "    if (epoch + 1) % 100 == 0: \n",
    "        print(f\"\"\"Epoch [{epoch + 1}/{epochs}],\n",
    "              Training Loss: {loss.item():.4f},\n",
    "              Validation Loss: {val_loss.item():.4f}\"\"\")\n",
    "\n",
    "end_time = time.time()\n",
    "training_time = end_time - start_time\n",
    "\n",
    "# Restore best model\n",
    "model_eos.load_state_dict(best_model_state)\n",
    "print(f\"Training finished. Best validation loss: {best_val_loss:.4f}\")\n",
    "\n",
    "# Plot Training Loss\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(training_losses, label=\"Training Loss\")\n",
    "plt.plot(val_losses, label=\"Validation Loss\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "plt.title(\"Training Loss in eos model\")\n",
    "plt.grid()\n",
    "\n",
    "fig_loc = \"/home/kay/ML-for-Neutron-Stars/COMMA_emulator/Outputs-Kay/TD_Models/\"\n",
    "fig_name = f\"{Model_num}_Losses.png\"\n",
    "plt.savefig(fig_loc+fig_name, dpi=300, bbox_inches='tight')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dfff160",
   "metadata": {},
   "source": [
    "### <div style= 'color: goldenrod'> Save trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d2cbf5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save trained model\n",
    "network_loc = \"/home/kay/ML-for-Neutron-Stars/COMMA_emulator/Outputs-Kay/TD_Models/\"\n",
    "network_name = f\"{Model_num}_hybridPP_nn.pth\"\n",
    "torch.save(model_eos.state_dict(), network_loc+network_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ffe64e8",
   "metadata": {},
   "source": [
    "### <div style= 'color: goldenrod'> Save model details to a text file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eb257d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_loc = \"/home/kay/ML-for-Neutron-Stars/COMMA_emulator/Outputs-Kay/TD_Models/\"\n",
    "file_name = Model_num+\"_details.txt\"\n",
    "\n",
    "with open(file_loc + file_name, \"w\") as f:\n",
    "    f.write(f\"{Model_num} DETAILS\\n\\n\")\n",
    "    f.write(\"Number of dimensions:\\n\")\n",
    "    f.write(f\"input_dims: {model_eos.fc1.in_features}\\n\")\n",
    "    f.write(f\"hidden_dims: {model_eos.fc1.out_features}\\n\")\n",
    "    f.write(f\"output_dims: {model_eos.fc3.out_features}\\n\\n\")\n",
    "    f.write(f\"Number of samples: {num_samples}\\n\\n\")\n",
    "    f.write(f\"epochs: {epochs}\\n\\n\")\n",
    "    f.write(f\"delta of criterion: {criterion.delta}\\n\\n\")\n",
    "    f.write(f\"optimizer: Adam\\n\\n\")\n",
    "    f.write(f\"learning rate: {optimizer.param_groups[0]['lr']}\\n\\n\")\n",
    "    f.write(f\"Training stopped at epoch: {epoch+1}\\n\")\n",
    "    f.write(f\"training_time_seconds: {training_time:.2f}\\n\")\n",
    "    f.write(f\"Best validation loss: {best_val_loss:.4f}\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95a0e5c7",
   "metadata": {},
   "source": [
    "### <div style= 'color: yellow'>Model Evaluation and comparison on Testing (unseen) data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63409317-67b5-414f-bb0f-72b4cffcdd3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_points = 50\n",
    "# Prepare ranges for L and Ksym\n",
    "L_values = [30., 50., 70.]  \n",
    "Ksym_values = [-300., -100., 100.]  \n",
    "\n",
    "# Initialize lists to store results\n",
    "predicted_TD = []\n",
    "original_TD = []\n",
    "original_mass = []\n",
    "original_radius = []\n",
    "\n",
    "# Iterate over all L and Ksym values\n",
    "for L in L_values:\n",
    "    for Ksym in Ksym_values:\n",
    "        ee, pp, nb, cs, icc = EoS([L, Ksym])\n",
    "        # Check conditions\n",
    "        if icc == 0 and max(pp) > pcmin:\n",
    "            # Create pressure grid\n",
    "            pc_array = np.logspace(np.log10(pcmin), np.log10(max(pp)), num_points)\n",
    "            \n",
    "            # Calculate original mass and radius using TOV\n",
    "            M_orig, R_orig, TD_orig = get_MRL_pc([L, Ksym], pc_array)\n",
    "\n",
    "            # Convert to NumPy arrays for element-wise operations\n",
    "            M_orig = np.array(M_orig)\n",
    "            TD_orig = np.array(TD_orig)\n",
    "            R_orig = np.array(R_orig)\n",
    "\n",
    "            # Find first maxima in mass array\n",
    "            j, mmax = find_first_maxima(M_orig) # mmax is the maximum mass\n",
    "        \n",
    "            # Slice and convert to log10\n",
    "            pc_array = pc_array[:j]\n",
    "            log_pc_array = np.log10(pc_array)\n",
    "            mass_orig = M_orig[:j]\n",
    "            TD_orig = TD_orig[:j]\n",
    "            R_orig = R_orig[:j]\n",
    "\n",
    "            # Prepare input for each pc point: [log_pc, L, Ksym]\n",
    "            input_array = np.column_stack([\n",
    "                            log_pc_array,\n",
    "                            np.full_like(log_pc_array, L),\n",
    "                                np.full_like(log_pc_array, Ksym)\n",
    "                                            ])\n",
    "            \n",
    "            input_tensor = torch.tensor(input_array, dtype=torch.float32)\n",
    "            \n",
    "            # Normalize the input data using the training mean and std\n",
    "            input_norm = (input_tensor - X_eos_mean) / X_eos_std\n",
    "            \n",
    "            # Make predictions with the trained model\n",
    "            with torch.no_grad():  \n",
    "                prediction = model_eos(input_norm)\n",
    "            \n",
    "            # Convert the prediction tensor to NumPy and denormalize the predicted mass and radius\n",
    "            # Get all predictions\n",
    "            prediction_np = prediction.detach().numpy()  # shape: (N, 2)\n",
    "\n",
    "            # # Denormalize each column\n",
    "            # TD_pred_log = prediction_np[:, 0] * y_eos_std + y_eos_mean\n",
    "            # # Convert back from log scale\n",
    "            # TD_pred = 10**TD_pred_log\n",
    "\n",
    "            # Denormalize each column\n",
    "            TD_pred_log = prediction_np[:, 0] * y_eos_std[0].item() + y_eos_mean[0].item()\n",
    "            # Convert back from log scale\n",
    "            TD_pred = 10**TD_pred_log\n",
    "\n",
    "            # After iterating over pc, store the results for each kappa, gamma pair\n",
    "            predicted_TD.append(TD_pred)\n",
    "            original_mass.append(mass_orig)\n",
    "            original_TD.append(TD_orig)\n",
    "            original_radius.append(R_orig)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "592cda95",
   "metadata": {},
   "source": [
    "### <div style= 'color: goldenrod'> Define a function to print the regression metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ebf7259",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "def regression_metrics(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Compute common regression metrics for comparing predictions with true values.\n",
    "    \n",
    "    Parameters:\n",
    "        y_true (array-like): Ground truth values\n",
    "        y_pred (array-like): Predicted values\n",
    "    \n",
    "    Returns:\n",
    "        dict: Dictionary containing MAE, MSE, RMSE, and R²\n",
    "    \"\"\"\n",
    "\n",
    "    y_true = np.array(y_true)\n",
    "    y_pred = np.array(y_pred)\n",
    "\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    mse = mean_squared_error(y_true, y_pred)\n",
    "    rmse = np.sqrt(mse)\n",
    "    r2 = r2_score(y_true, y_pred)\n",
    "\n",
    "    return {\n",
    "        \"MAE\": np.round(mae,2),\n",
    "        \"MSE\": np.round(mse,2),\n",
    "        \"RMSE\": rmse,\n",
    "        \"R^2\": np.round(r2,2),\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74d82c07",
   "metadata": {},
   "source": [
    "### <div style= 'color: yellow'> Regression metrics for tidal deformability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ad40c23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Regression metrics for tidal deformability\n",
    "import json\n",
    "original_TD_flat=np.concatenate (original_TD).astype(float)\n",
    "predicted_TD_flat=np.concatenate(predicted_TD).astype(float)\n",
    "results = regression_metrics(original_TD_flat, predicted_TD_flat)\n",
    "print(json.dumps(results, indent = 4))\n",
    "\n",
    "with open(file_loc + file_name, \"a\") as f:\n",
    "    f.write(f\"\\nTidal Deformability Regression Metrics:\\n\")\n",
    "    for key, value in results.items():\n",
    "        f.write(f\"{key}: {value}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b46e139",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(13, 6))\n",
    "\n",
    "# Create a color map\n",
    "colors = plt.cm.viridis(np.linspace(0, 1, len(L_values) * len(Ksym_values)))\n",
    "\n",
    "# Iterate and assign the same color to TOV and NN prediction\n",
    "for i, (L, Ksym) in enumerate([(k, g) for k in L_values for g in Ksym_values]):\n",
    "    color = colors[i]\n",
    "    plt.plot(original_TD[i], original_TD[i], label= \"Original_TD\", linestyle='-', color=color)\n",
    "    plt.plot(original_TD[i], predicted_TD[i], label= \"Predicted TD\", linestyle='--', color=color)\n",
    "\n",
    "plt.xlabel(\"Original TD\")\n",
    "plt.ylabel(\"Original and Predicted TD\")\n",
    "\n",
    "plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left', borderaxespad=0.)\n",
    "plt.title(\"Comparison of TOV and Neural Network Predictions\")\n",
    "plt.grid()\n",
    "plt.tight_layout()\n",
    "\n",
    "fig_loc = \"/home/kay/ML-for-Neutron-Stars/COMMA_emulator/Outputs-Kay/TD_Models/\"\n",
    "fig_name = f\"{Model_num}_Testing_accuracy.png\"\n",
    "plt.savefig(fig_loc+fig_name, dpi=300, bbox_inches='tight')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9a624d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(13, 6))\n",
    "\n",
    "# Create a color map\n",
    "colors = plt.cm.viridis(np.linspace(0, 1, len(L_values) * len(Ksym_values)))\n",
    "\n",
    "# Iterate and assign the same color to TOV and NN prediction\n",
    "for i, (L, Ksym) in enumerate([(k, g) for k in L_values for g in Ksym_values]):\n",
    "    color = colors[i]\n",
    "    plt.scatter(original_TD[i], (original_TD[i]-predicted_TD[i]), color=color)\n",
    "\n",
    "plt.xlabel(\"Predicted TD\")\n",
    "plt.ylabel(\"Residuals = Original TD - Predicted TD\")\n",
    "plt.title(\"Residual plot\")\n",
    "plt.grid()\n",
    "plt.tight_layout()\n",
    "\n",
    "fig_loc = \"/home/kay/ML-for-Neutron-Stars/COMMA_emulator/Outputs-Kay/TD_Models/\"\n",
    "fig_name = f\"{Model_num}_Testing_accuracy_scatter.png\"\n",
    "plt.savefig(fig_loc+fig_name, dpi=300, bbox_inches='tight')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "163243b4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "116568c5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
