{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5780274b",
   "metadata": {},
   "source": [
    "# LECTURE 1:  A very simple NN (input to output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "040188b9",
   "metadata": {},
   "source": [
    "Seeing what is happening during feedforeward within a fully connected layer.\n",
    "\n",
    "$$z_j = \\sum_{k} w_{jk} * y_k^{in} + b_j$$\n",
    "\n",
    "$$y_{j}^{out} = f(z_{j})$$\n",
    "\n",
    "where:\n",
    "* $j$ is the output index and $k$ is the inpout index\n",
    "* $w_{jk}$ is the weight matrix\n",
    "* $y_k^{in}$ is the input vector (neuron)\n",
    "* $y_{j}^{out}$ is the output vector (neuron)\n",
    "* $b_j$ is the bias vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5a3c515c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "061a89aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "N_in = 3 # input layer size\n",
    "N_out = 2 # output layer size\n",
    "\n",
    "w = np.random.uniform(low = -1, high = 1, size = (N_out, N_in)) # random weights\n",
    "b = np.random.uniform(low = -1, high = 1, size = N_out) # random biases : N_out vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a374fb76",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_in = np.array([0.2, 0.4, -0.1]) # input vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cfd6a56",
   "metadata": {},
   "outputs": [],
   "source": [
    "z = np.dot(w, y_in) + b # result: the z vector of length N_out\n",
    "y_out = 1/(1 + np.exp(-z)) # sigmoid activation function (applied element-wise )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1f3aa1fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input:\n",
      " [ 0.2  0.4 -0.1]\n",
      "Output after activation (y_out):\n",
      " [0.53031715 0.61818701]\n",
      "Weights:\n",
      " [[-0.92372962  0.18871367  0.91210246]\n",
      " [ 0.52160159 -0.54131305 -0.84025871]]\n",
      "Biases:\n",
      " [0.32188825 0.51003911]\n",
      "Pre-activation (z):\n",
      " [0.12141755 0.48186008]\n"
     ]
    }
   ],
   "source": [
    "print(\"Input:\\n\", y_in)\n",
    "print(\"Output after activation (y_out):\\n\", y_out)\n",
    "\n",
    "print(\"Weights:\\n\", w)\n",
    "print(\"Biases:\\n\", b)\n",
    "print(\"Pre-activation (z):\\n\", z)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88f45b89",
   "metadata": {},
   "source": [
    "To visualize a neural network look at the lecture."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a93315b",
   "metadata": {},
   "source": [
    "To also visualize multi layer networks look at the lecture"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
