{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "00c67d37",
   "metadata": {},
   "source": [
    "# TOV Emulator to train a NN to predict just Maximum Mass of a Neutron Star from a Neuclear EOS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a069fca5",
   "metadata": {},
   "source": [
    "### <div style= 'color: goldenrod'> Import all the required modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8f6b2ebf-5f02-4974-899d-31d68abf69b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from numpy import pi as pi\n",
    "from scipy.integrate import odeint\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import time # to meaasure execution time of code blocks\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "\n",
    "# Custom modules\n",
    "import eos # generates EOS tables. Returns energy density, pressure, etc. for given set of EOS parameters. \n",
    "import tov # solves TOV equations and returns mass and radius for a given EOS and central pressure\n",
    "import tov_tide # solves TOV equations including tidal deformability calculations, for neutron star tidal effects in binaries.\n",
    "\n",
    "\n",
    "%matplotlib widget"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00b6c96f",
   "metadata": {},
   "source": [
    "### <div style= 'color: goldenrod'> Define the following functions:\n",
    "$EoS(\\theta)$:\n",
    "Generate the energy density and pressure arrays for a given EOS parameter set.\n",
    "\n",
    "$find\\_first\\_maxima$:\n",
    "Find first local maxima (to get NS mass)\n",
    "\n",
    "$get\\_MR\\_pc$:\n",
    "Solve TOV equations to get mass-radius points for an array of central pressures.\n",
    "\n",
    "$get\\_MRL\\_pc$:\n",
    "Solve TOV equations to get mass, radius and tidal deformability points for an array of central pressures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "db23591c-6f82-4bb1-963e-1203c965a9cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "dkm = 1.3234e-6 # conversion of energy density and pressure from Mev/fm^3 to km^-2\n",
    "conv = 197.33**3 # MeV/fm3 is roughly h_bar * c in natural units\n",
    "pcmin = 1.33e-6 # Fiducial minimum central pressure used when generating neutron star sequences\n",
    "                # Ensures TOV solver starts with a non-zero pressure \n",
    "\n",
    "\n",
    "def EoS(θ):\n",
    "    \"\"\"\n",
    "    Generate the energy density and pressure arrays for a given EOS parameter set.\n",
    "    Returns Energy and pressure array given given eos parameters and if eos is not montonic returns nan.\n",
    "    \n",
    "    Parameters:\n",
    "    ----------\n",
    "    θ = [L0, Ksym]: parameters of the nuclear EOS.\n",
    "            \n",
    "            L0: slope of symmetry energy. Controls how neutron-rich matter pressure grows with density.\n",
    "            Ksym: curvature of symmetry energy. Determines how “stiff” the EOS is for neutron-rich matter at higher densities.\n",
    "    \n",
    "    Returns:\n",
    "    -------\n",
    "    nb: baryon number density array\n",
    "    ener: energy density at each density point array\n",
    "    pres: pressure at each density point array\n",
    "    cs: speed of sound array\n",
    "    icc: flag if EOS is causal or monotonic\n",
    "\n",
    "    \"\"\"\n",
    "    L0, Ksym = θ[0], θ[1]\n",
    "    # Calling the eos.eos module\n",
    "    index, nb, pressure, energy, cs, icc = eos.eos(L0, Ksym, 1.6, 3.0, 6.2, 3.7, 2.4, 2.6)\n",
    "    # Truncate arrays up to index-1 to ensure valid, monotonic EOS.\n",
    "    nb = nb[0:index-1] \n",
    "    pressure = pressure[0:index-1]\n",
    "    energy = energy[0:index-1]\n",
    "    cs = cs[0:index-1]\n",
    "    # Converts pressure and energy to km^-2 units\n",
    "    pres = pressure * dkm\n",
    "    ener = energy * dkm\n",
    "    return ener, pres, nb, cs, icc\n",
    "\n",
    "################################################################################\n",
    "\n",
    "def get_MR_pc(θ, pc):\n",
    "    \"\"\"\n",
    "    Solve TOV equations to get mass-radius points for an array of central pressures.\n",
    "\n",
    "    Parameters:\n",
    "    ----------\n",
    "    θ: [L0, Ksym] EOS parameters\n",
    "    pc: array of entral pressures\n",
    "\n",
    "    Returns:\n",
    "    -------\n",
    "    M: List of Masses\n",
    "    R: List of Radiuses corresponding to each central pressure\n",
    "\n",
    "    \"\"\"\n",
    "    M=[]\n",
    "    R=[]\n",
    "    for i in pc:\n",
    "        L0, Ksym = θ[0], θ[1]\n",
    "        # Calling the eos.eos module\n",
    "        index, nb, pressure, energy, cs, icc = eos.eos(L0, Ksym, 1.6, 3.0, 6.2, 3.7, 2.4, 2.6)\n",
    "        pressure = pressure[0:index-1]\n",
    "        energy = energy[0:index-1]\n",
    "        pres = pressure * dkm\n",
    "        ener = energy * dkm\n",
    "        # Calling the tov.tov module\n",
    "        m, r = tov.tov(ener, pres, [i])\n",
    "        M.append(m)\n",
    "        R.append(r)\n",
    "    return M, R\n",
    "    \n",
    "################################################################################\n",
    "\n",
    "def get_MRL_pc(θ, pc):\n",
    "    \"\"\"\n",
    "    Solve TOV equations to get mass, radius and tidal deformability points for an array of central pressures.\n",
    "\n",
    "    Parameters:\n",
    "    ----------\n",
    "    θ: [L0, Ksym] EOS parameters\n",
    "    pc: array of central pressures\n",
    "\n",
    "    Returns:\n",
    "    -------\n",
    "    M: List of Masses\n",
    "    R: List of Radiuses \n",
    "    L: List of Tidal deformabilities corresponding to each central pressure\n",
    "    \"\"\"\n",
    "    M=[]\n",
    "    R=[]\n",
    "    L=[]\n",
    "    for i in pc:\n",
    "        L0, Ksym = θ[0] ,θ[1]\n",
    "        # Calling the eos.eos module\n",
    "        index, nb, pressure, energy, cs, icc = eos.eos(L0, Ksym, 1.6, 3.0, 6.2, 3.7, 2.4, 2.6)\n",
    "        pressure = pressure[0:index-1]\n",
    "        energy = energy[0:index-1]\n",
    "        pres = pressure * dkm\n",
    "        ener = energy * dkm\n",
    "        # Calling the tov_tide.tov_tide module\n",
    "        m, r, td = tov_tide.tov_tide(ener, pres, [i])\n",
    "        M.append(m)\n",
    "        R.append(r)\n",
    "        L.append(td)\n",
    "    return M, R, L\n",
    "\n",
    "################################################################################\n",
    "\n",
    "def find_first_maxima(arr):\n",
    "    \"\"\"\n",
    "    Identify the first peak in a 1D array (used to find maximum neutron star mass).\n",
    "    Loops through array to check if an element is larger than its neighbors → first local maximum.\n",
    "    If no local maxima found, returns global maximum as fallback.\n",
    "\n",
    "    Parameters:\n",
    "    ----------\n",
    "    arr: mass array\n",
    "\n",
    "    Returns:\n",
    "    -------\n",
    "    max_index: index of the first maxima\n",
    "    arr[max_index]: mass value of the first maxima\n",
    "\n",
    "    \"\"\"\n",
    "    for i in range(1, len(arr) - 1):\n",
    "        if arr[i] > arr[i - 1] and arr[i] > arr[i + 1]:\n",
    "            return i, arr[i]  # Return the index and the value of the first maxima\n",
    "    max_index = np.argmax(arr)\n",
    "    return max_index, arr[max_index]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37ae57b5",
   "metadata": {},
   "source": [
    "### <div style= 'color: yellow'> Load the generated dataset, normalizing it and splitting into training and validation datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8f87ef44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset preview with 1000 samples:\n",
      "     log_pc          L       Ksym      Mass     Radius  TidalDeformability\n",
      "0 -5.876148  58.694477  10.576015  0.098653  69.920286        3.214959e+09\n",
      "1 -5.814806  58.694477  10.576015  0.105419  45.475846        3.927776e+08\n",
      "2 -5.753463  58.694477  10.576015  0.114403  33.544300        1.194948e+08\n",
      "3 -5.692121  58.694477  10.576015  0.125518  26.768894        5.534953e+07\n",
      "4 -5.630778  58.694477  10.576015  0.138802  22.545374        2.997355e+07\n",
      "5 -5.569436  58.694477  10.576015  0.154310  19.748377        1.727188e+07\n",
      "6 -5.508093  58.694477  10.576015  0.172184  17.809922        1.022104e+07\n",
      "7 -5.446751  58.694477  10.576015  0.192556  16.425164        6.129059e+06\n",
      "8 -5.385408  58.694477  10.576015  0.215581  15.414005        3.716365e+06\n",
      "9 -5.324065  58.694477  10.576015  0.241471  14.664074        2.263645e+06\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 29\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m L \u001b[38;5;129;01min\u001b[39;00m valid_EOS_params[:,\u001b[38;5;241m0\u001b[39m]:\n\u001b[1;32m     28\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m K_sym \u001b[38;5;129;01min\u001b[39;00m valid_EOS_params[:,\u001b[38;5;241m1\u001b[39m]:\n\u001b[0;32m---> 29\u001b[0m         j, mmax \u001b[38;5;241m=\u001b[39m \u001b[43mfind_first_maxima\u001b[49m\u001b[43m(\u001b[49m\u001b[43mMRL_data\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     30\u001b[0m         max_masses\u001b[38;5;241m.\u001b[39mappend(mmax)\n\u001b[1;32m     32\u001b[0m \u001b[38;5;66;03m# Prepare X (features) and y (targets)\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[2], line 127\u001b[0m, in \u001b[0;36mfind_first_maxima\u001b[0;34m(arr)\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mfind_first_maxima\u001b[39m(arr):\n\u001b[1;32m    112\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;124;03m    Identify the first peak in a 1D array (used to find maximum neutron star mass).\u001b[39;00m\n\u001b[1;32m    114\u001b[0m \u001b[38;5;124;03m    Loops through array to check if an element is larger than its neighbors → first local maximum.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    125\u001b[0m \n\u001b[1;32m    126\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 127\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28;43mrange\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43marr\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m:\n\u001b[1;32m    128\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m arr[i] \u001b[38;5;241m>\u001b[39m arr[i \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m] \u001b[38;5;129;01mand\u001b[39;00m arr[i] \u001b[38;5;241m>\u001b[39m arr[i \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m]:\n\u001b[1;32m    129\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m i, arr[i]  \u001b[38;5;66;03m# Return the index and the value of the first maxima\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "num_samples = 1000 #############################################################\n",
    "\n",
    "# Load dataset saved with np.savez\n",
    "dataset_name = f\"EOS_dataset_{num_samples}samples.npz\"\n",
    "dataset_loc = \"/home/kay/ML-for-Neutron-Stars/COMMA_emulator/Outputs-Kay/Datasets/\"\n",
    "data = np.load(dataset_loc+dataset_name)\n",
    "\n",
    "# Extract columns\n",
    "log_pc_samples = data['log_pc_samples']     # shape: (N,)\n",
    "valid_EOS_params = data['valid_EOS_params'] # shape: (N, 2)\n",
    "MRL_data = data['MRL_data']                 # shape: (N, 3)\n",
    "\n",
    "# Visualizing the dataset\n",
    "df = pd.DataFrame(\n",
    "    np.column_stack([log_pc_samples, valid_EOS_params, MRL_data]),\n",
    "    columns=[\"log_pc\", \"L\", \"Ksym\", \"Mass\", \"Radius\", \"TidalDeformability\"]\n",
    ")\n",
    "n = int(re.search(r\"\\d+\", dataset_name).group())\n",
    "print(f\"Dataset preview with {n} samples:\")\n",
    "print(df.head(10))  # nicely formatted table of the first 10 values\n",
    "\n",
    "# Extract max masses from MRL_data\n",
    "max_masses = []\n",
    "for L in valid_EOS_params[:,0]:\n",
    "    for K_sym in valid_EOS_params[:,1]:\n",
    "        j, mmax = find_first_maxima(MRL_data[:, 0])\n",
    "        max_masses.append(mmax)\n",
    "\n",
    "# Prepare X (features) and y (targets)\n",
    "X_max_mass = torch.tensor(valid_EOS_params, dtype=torch.float32)  # shape (N, 2)\n",
    "y_max_mass = torch.tensor(max_masses, dtype=torch.float32).view(-1, 1)\n",
    "print(y_max_mass)\n",
    "\n",
    "# Normalize the dataset\n",
    "X_max_mass_mean, X_max_mass_std = X_max_mass.mean(dim=0), X_max_mass.std(dim=0)\n",
    "y_max_mass_mean, y_max_mass_std = y_max_mass.mean(dim=0), y_max_mass.std(dim=0)\n",
    "X_max_mass_norm = (X_max_mass - X_max_mass_mean) / X_max_mass_std\n",
    "y_max_mass_norm = (y_max_mass - y_max_mass_mean) / y_max_mass_std\n",
    "\n",
    "# Split into training and validation sets\n",
    "train_size = int(0.8 * len(X_max_mass_norm))\n",
    "X_max_mass_train, X_max_mass_val = X_max_mass_norm[:train_size], X_max_mass_norm[train_size:]\n",
    "y_max_mass_train, y_max_mass_val = y_max_mass_norm[:train_size], y_max_mass_norm[train_size:]\n",
    "\n",
    "# Convert data to PyTorch tensors\n",
    "X_max_mass_train, y_max_mass_train = X_max_mass_train.view(-1, 2), y_max_mass_train.view(-1, 1)\n",
    "X_max_mass_val, y_max_mass_val = X_max_mass_val.view(-1, 2), y_max_mass_val.view(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8bad3b92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.09865343, 0.10541941, 0.11440332, ..., 2.16629643, 2.17592478,\n",
       "       2.17992702], shape=(45716,))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MRL_data[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e962fc76",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  10.57601536,   10.57601536,   10.57601536, ..., -110.61349473,\n",
       "       -110.61349473, -110.61349473], shape=(45716,))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_EOS_params[:,1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6fd97a5",
   "metadata": {},
   "source": [
    "### <div style= 'color: yellow'> Defining and training the NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1aaaecae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set model number for saving\n",
    "Model_num = \"MaxMass_Model1\" ###########################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "24340c79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Neural Network for EOS predictions\n",
    "class HybridPP_EOS_NN(nn.Module):\n",
    "    def __init__(self, input_dim=3, hidden_dim=100, output_dim=1): #############\n",
    "        super(HybridPP_EOS_NN, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, hidden_dim)\n",
    "        self.fc2 = nn.Linear(hidden_dim, hidden_dim)\n",
    "        self.fc3 = nn.Linear(hidden_dim, hidden_dim//2)\n",
    "        self.fc4 = nn.Linear(hidden_dim//2, output_dim)\n",
    "        self.relu = nn.SiLU()\n",
    "        self.dropout = nn.Dropout(p=0.2) # Dropout layer for regularization\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.relu(self.fc2(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.relu(self.fc3(x))\n",
    "        x = self.dropout(x)\n",
    "        return self.fc4(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4dd591de-f663-4c7a-8fa8-fad78b8a9bc1",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (36572x2 and 3x100)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 52\u001b[0m\n\u001b[1;32m     50\u001b[0m model_eos\u001b[38;5;241m.\u001b[39mtrain() \u001b[38;5;66;03m# Training mode\u001b[39;00m\n\u001b[1;32m     51\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad() \u001b[38;5;66;03m# Erase the record of gradients\u001b[39;00m\n\u001b[0;32m---> 52\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel_eos\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_max_mass_train\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# Forward pass\u001b[39;00m\n\u001b[1;32m     53\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(outputs, y_max_mass_train) \u001b[38;5;66;03m# Compute training loss\u001b[39;00m\n\u001b[1;32m     54\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward() \u001b[38;5;66;03m# Backward propogate the training loss\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/ML/lib/python3.10/site-packages/torch/nn/modules/module.py:1751\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1749\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1751\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/ML/lib/python3.10/site-packages/torch/nn/modules/module.py:1762\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1757\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1758\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1760\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1761\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1762\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1764\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1765\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "Cell \u001b[0;32mIn[5], line 13\u001b[0m, in \u001b[0;36mHybridPP_EOS_NN.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[0;32m---> 13\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrelu(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfc1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m     14\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout(x)\n\u001b[1;32m     15\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrelu(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfc2(x))\n",
      "File \u001b[0;32m~/miniconda3/envs/ML/lib/python3.10/site-packages/torch/nn/modules/module.py:1751\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1749\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1751\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/ML/lib/python3.10/site-packages/torch/nn/modules/module.py:1762\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1757\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1758\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1760\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1761\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1762\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1764\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1765\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/miniconda3/envs/ML/lib/python3.10/site-packages/torch/nn/modules/linear.py:125\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    124\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 125\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (36572x2 and 3x100)"
     ]
    }
   ],
   "source": [
    "# Initialize and train the model\n",
    "model_eos = HybridPP_EOS_NN()\n",
    "criterion = nn.HuberLoss(delta=1.0)\n",
    "optimizer = optim.AdamW(model_eos.parameters(), lr=1e-3, weight_decay=1e-5) #######################\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "epochs = 10000 #################################################################\n",
    "training_losses = []\n",
    "val_losses = []\n",
    "\n",
    "best_val_loss = float('inf')\n",
    "patience = 300  # Number of epochs to wait for improvement before stopping\n",
    "patience_counter = 0\n",
    "\n",
    "# # Batching the data\n",
    "# batch_size = 16  ###############################################################\n",
    "\n",
    "# train_dataset = TensorDataset(X_max_mass_train, y_max_mass_train)\n",
    "# val_dataset = TensorDataset(X_max_mass_val, y_max_mass_val)\n",
    "\n",
    "# train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "# val_loader = DataLoader(val_dataset, batch_size=batch_size)\n",
    "\n",
    "# for epoch in range(epochs):\n",
    "#     model_eos.train()\n",
    "#     epoch_train_loss = 0\n",
    "#     for X_batch, y_batch in train_loader:\n",
    "#         optimizer.zero_grad()\n",
    "#         outputs = model_eos(X_batch)\n",
    "#         loss = criterion(outputs, y_batch)\n",
    "#         loss.backward()\n",
    "#         optimizer.step()\n",
    "#         epoch_train_loss += loss.item() * X_batch.size(0)\n",
    "#     training_losses.append(epoch_train_loss / len(train_loader.dataset))\n",
    "\n",
    "#     # Validation\n",
    "#     model_eos.eval()\n",
    "#     epoch_val_loss = 0\n",
    "#     with torch.no_grad():\n",
    "#         for X_batch, y_batch in val_loader:\n",
    "#             val_outputs = model_eos(X_batch)\n",
    "#             val_loss = criterion(val_outputs, y_batch)\n",
    "#             epoch_val_loss += val_loss.item() * X_batch.size(0)\n",
    "#     val_losses.append(epoch_val_loss / len(val_loader.dataset))\n",
    "\n",
    "# Without batching (original code)\n",
    "for epoch in range(epochs):\n",
    "    # Training\n",
    "    model_eos.train() # Training mode\n",
    "    optimizer.zero_grad() # Erase the record of gradients\n",
    "    outputs = model_eos(X_max_mass_train) # Forward pass\n",
    "    loss = criterion(outputs, y_max_mass_train) # Compute training loss\n",
    "    loss.backward() # Backward propogate the training loss\n",
    "    optimizer.step()\n",
    "    training_losses.append(loss.item())\n",
    "\n",
    "    # Validation\n",
    "    model_eos.eval() # Validation mode\n",
    "    with torch.no_grad():\n",
    "        val_outputs = model_eos(X_max_mass_val)\n",
    "        val_loss = criterion(val_outputs, y_max_mass_val)\n",
    "        val_losses.append(val_loss.item())\n",
    "\n",
    "    # Early stopping check\n",
    "    if val_loss.item() < best_val_loss:\n",
    "        best_val_loss = val_loss.item()\n",
    "        patience_counter = 0\n",
    "        # Save the best model weights\n",
    "        best_model_state = model_eos.state_dict()\n",
    "    else:\n",
    "        patience_counter += 1\n",
    "        if patience_counter >= patience:\n",
    "            print(f\"Early stopping at epoch {epoch+1}\")\n",
    "            break\n",
    "\n",
    "    # Print progress every 100 epochs\n",
    "    if (epoch + 1) % 100 == 0: \n",
    "        print(f\"\"\"Epoch [{epoch + 1}/{epochs}],\n",
    "              Training Loss: {loss.item():.4f},\n",
    "              Validation Loss: {val_loss.item():.4f}\"\"\")\n",
    "\n",
    "end_time = time.time()\n",
    "training_time = end_time - start_time\n",
    "\n",
    "# Restore best model\n",
    "model_eos.load_state_dict(best_model_state)\n",
    "print(f\"Training finished. Best validation loss: {best_val_loss:.4f}\")\n",
    "\n",
    "# Plot Training Loss\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(training_losses, label=\"Training Loss\")\n",
    "plt.plot(val_losses, label=\"Validation Loss\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "plt.title(\"Training Loss in eos model\")\n",
    "plt.grid()\n",
    "\n",
    "fig_loc = \"/home/kay/ML-for-Neutron-Stars/COMMA_emulator/Outputs-Kay/MaxMass_Models/\"\n",
    "fig_name = f\"{Model_num}_Losses.png\"\n",
    "plt.savefig(fig_loc+fig_name, dpi=300, bbox_inches='tight')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dfff160",
   "metadata": {},
   "source": [
    "### <div style= 'color: goldenrod'> Save trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d2cbf5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save trained model\n",
    "network_loc = \"/home/kay/ML-for-Neutron-Stars/COMMA_emulator/Outputs-Kay/MaxMass_Models/\"\n",
    "network_name = f\"{Model_num}_hybridPP_nn.pth\"\n",
    "torch.save(model_eos.state_dict(), network_loc+network_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ffe64e8",
   "metadata": {},
   "source": [
    "### <div style= 'color: goldenrod'> Save model details to a text file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eb257d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_loc = \"/home/kay/ML-for-Neutron-Stars/COMMA_emulator/Outputs-Kay/MaxMass_Models/\"\n",
    "file_name = Model_num+\"_details.txt\"\n",
    "\n",
    "with open(file_loc + file_name, \"w\") as f:\n",
    "    f.write(f\"{Model_num} DETAILS\\n\\n\")\n",
    "    f.write(\"Number of dimensions:\\n\")\n",
    "    f.write(f\"input_dims: {model_eos.fc1.in_features}\\n\")\n",
    "    f.write(f\"hidden_dims: {model_eos.fc1.out_features}\\n\")\n",
    "    f.write(f\"output_dims: {model_eos.fc3.out_features}\\n\\n\")\n",
    "    f.write(f\"Number of samples: {num_samples}\\n\\n\")\n",
    "    f.write(f\"epochs: {epochs}\\n\\n\")\n",
    "    f.write(f\"delta of criterion: {criterion.delta}\\n\\n\")\n",
    "    f.write(f\"optimizer: Adam\\n\\n\")\n",
    "    f.write(f\"learning rate: {optimizer.param_groups[0]['lr']}\\n\\n\")\n",
    "    f.write(f\"Training stopped at epoch: {epoch+1}\\n\")\n",
    "    f.write(f\"training_time_seconds: {training_time:.2f}\\n\")\n",
    "    # f.write(f\"Best validation loss: {best_val_loss:.4f}\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95a0e5c7",
   "metadata": {},
   "source": [
    "### <div style= 'color: yellow'>Model Evaluation and comparison on Testing (unseen) data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63409317-67b5-414f-bb0f-72b4cffcdd3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_points = 50\n",
    "# Prepare ranges for L and Ksym\n",
    "L_values = [30., 50., 70.]  \n",
    "Ksym_values = [-300., -100., 100.]  \n",
    "\n",
    "# Initialize lists to store results\n",
    "original_max_mass = []\n",
    "predicted_max_mass= []\n",
    "\n",
    "# Iterate over all L and Ksym values\n",
    "for L in L_values:\n",
    "    for Ksym in Ksym_values:\n",
    "        ee, pp, nb, cs, icc = EoS([L, Ksym])\n",
    "        # Check conditions\n",
    "        if icc == 0 and max(pp) > pcmin:\n",
    "            # Create pressure grid\n",
    "            pc_array = np.logspace(np.log10(pcmin), np.log10(max(pp)), num_points)\n",
    "            \n",
    "            # Calculate original mass and radius using TOV\n",
    "            M_orig, R_orig, TD_orig = get_MRL_pc([L, Ksym], pc_array)\n",
    "\n",
    "            # Convert to NumPy arrays for element-wise operations\n",
    "            M_orig = np.array(M_orig)\n",
    "            TD_orig = np.array(TD_orig)\n",
    "            R_orig = np.array(R_orig)\n",
    "\n",
    "            # Find first maxima in mass array\n",
    "            j, mmax = find_first_maxima(M_orig) # mmax is the maximum mass\n",
    "\n",
    "            print(mmax)\n",
    "            \n",
    "        \n",
    "\n",
    "\n",
    "            # # Prepare input for each pc point: [log_pc, L, Ksym]\n",
    "            # input_array = np.column_stack([\n",
    "            #                 log_pc_array,\n",
    "            #                 np.full_like(log_pc_array, L),\n",
    "            #                     np.full_like(log_pc_array, Ksym)\n",
    "            #                                 ])\n",
    "            \n",
    "            # input_tensor = torch.tensor(input_array, dtype=torch.float32)\n",
    "            \n",
    "            # # Normalize the input data using the training mean and std\n",
    "            # input_norm = (input_tensor - X_max_mass_mean) / X_max_mass_std\n",
    "            \n",
    "            # # Make predictions with the trained model\n",
    "            # with torch.no_grad():  \n",
    "            #     prediction = model_eos(input_norm)\n",
    "            \n",
    "            # # Convert the prediction tensor to NumPy and denormalize the predicted mass and radius\n",
    "            # # Get all predictions\n",
    "            # prediction_np = prediction.detach().numpy()  # shape: (N, 2)\n",
    "\n",
    "            # # Denormalize each column\n",
    "            # TD_pred = prediction_np[:, 0] * y_max_mass_std[0].item() + y_max_mass_mean[0].item()\n",
    "\n",
    "            # # After iterating over pc, store the results for each kappa, gamma pair\n",
    "            # original_max_mass.append(mmax)\n",
    "            # predicted_max_mass.append(max(TD_pred))  # Store the maximum predicted TD for this"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "592cda95",
   "metadata": {},
   "source": [
    "### <div style= 'color: goldenrod'> Define a function to print the regression metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ebf7259",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "def regression_metrics(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Compute common regression metrics for comparing predictions with true values.\n",
    "    \n",
    "    Parameters:\n",
    "        y_true (array-like): Ground truth values\n",
    "        y_pred (array-like): Predicted values\n",
    "    \n",
    "    Returns:\n",
    "        dict: Dictionary containing MAE, MAPE, MSE, RMSE, R², and Log-MAE\n",
    "    \"\"\"\n",
    "\n",
    "    y_true = np.array(y_true)\n",
    "    y_pred = np.array(y_pred)\n",
    "\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    mse = mean_squared_error(y_true, y_pred)\n",
    "    rmse = np.sqrt(mse)\n",
    "    r2 = r2_score(y_true, y_pred)\n",
    "\n",
    "    return {\n",
    "        \"MAE\": np.round(mae,2),\n",
    "        \"MSE\": np.round(mse,2),\n",
    "        \"RMSE\": rmse,\n",
    "        \"R^2\": np.round(r2,2),\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74d82c07",
   "metadata": {},
   "source": [
    "### <div style= 'color: yellow'> Regression metrics for tidal deformability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ad40c23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Regression metrics for tidal deformability\n",
    "import json\n",
    "original_TD_flat=np.concatenate (original_TD).astype(float)\n",
    "predicted_TD_flat=np.concatenate(predicted_TD).astype(float)\n",
    "results = regression_metrics(original_TD_flat, predicted_TD_flat)\n",
    "print(json.dumps(results, indent = 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b46e139",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(13, 6))\n",
    "\n",
    "# Create a color map\n",
    "colors = plt.cm.viridis(np.linspace(0, 1, len(L_values) * len(Ksym_values)))\n",
    "\n",
    "# Iterate and assign the same color to TOV and NN prediction\n",
    "for i, (L, Ksym) in enumerate([(k, g) for k in L_values for g in Ksym_values]):\n",
    "    color = colors[i]\n",
    "    plt.plot(original_TD[i], original_TD[i], label= \"Original_TD\", linestyle='-', color=color)\n",
    "    plt.plot(original_TD[i], predicted_TD[i], label= \"Predicted TD\", linestyle='--', color=color)\n",
    "\n",
    "plt.xlabel(\"Original TD\")\n",
    "plt.ylabel(\"Original and Predicted TD\")\n",
    "\n",
    "plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left', borderaxespad=0.)\n",
    "plt.title(\"Comparison of TOV and Neural Network Predictions\")\n",
    "plt.grid()\n",
    "plt.tight_layout()\n",
    "\n",
    "fig_loc = \"/home/kay/ML-for-Neutron-Stars/COMMA_emulator/Outputs-Kay/MaxMass_Models/\"\n",
    "fig_name = f\"{Model_num}_Testing_accuracy.png\"\n",
    "plt.savefig(fig_loc+fig_name, dpi=300, bbox_inches='tight')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9a624d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(13, 6))\n",
    "\n",
    "# Create a color map\n",
    "colors = plt.cm.viridis(np.linspace(0, 1, len(L_values) * len(Ksym_values)))\n",
    "\n",
    "# Iterate and assign the same color to TOV and NN prediction\n",
    "for i, (L, Ksym) in enumerate([(k, g) for k in L_values for g in Ksym_values]):\n",
    "    color = colors[i]\n",
    "    plt.scatter(original_TD[i], (original_TD[i]-predicted_TD[i]), color=color)\n",
    "\n",
    "plt.xlabel(\"Predicted TD\")\n",
    "plt.ylabel(\"Residuals = Original TD - Predicted TD\")\n",
    "plt.title(\"Residual plot\")\n",
    "plt.grid()\n",
    "plt.tight_layout()\n",
    "\n",
    "fig_loc = \"/home/kay/ML-for-Neutron-Stars/COMMA_emulator/Outputs-Kay/MaxMass_Models/\"\n",
    "fig_name = f\"{Model_num}_Testing_accuracy_scatter.png\"\n",
    "plt.savefig(fig_loc+fig_name, dpi=300, bbox_inches='tight')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "163243b4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "116568c5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
